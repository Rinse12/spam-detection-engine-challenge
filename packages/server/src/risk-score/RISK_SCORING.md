# Risk Scoring System

This document explains how EasyCommunitySpamBlocker calculates risk scores for publications.

## Overview

The risk score is a value between 0.0 and 1.0 that indicates the likelihood a publication is spam or malicious:

- **0.0 - 0.3**: Low risk (likely legitimate)
- **0.3 - 0.7**: Moderate risk (may require verification)
- **0.7 - 1.0**: High risk (likely spam/malicious)

The score is calculated as a weighted combination of multiple factors, each analyzing different aspects of the publication and its author.

## Trust Model

**Important**: Not all author data can be trusted equally.

- `author.subplebbit.*` fields are **PARTIALLY TRUSTED** - they are generated by the subplebbit, but subplebbit owners can manipulate them
- All other `author.*` fields are **UNTRUSTED** - they are provided by the user and can be faked

**Note on `author.wallets` and `author.avatar`**: These fields contain internal signatures, but plebbit-js only validates them during specific subplebbit challenges (e.g., EVM contract call challenge). When a client loads a comment by CID, these signatures are NOT automatically verified. This spam detection engine does not validate these signatures itself, so these fields should be treated as **UNTRUSTED** for risk scoring purposes. The wallet velocity factor uses wallet addresses for tracking but does not rely on them as proof of identity.

The risk scoring system primarily relies on `author.subplebbit` data for reputation signals, with mitigations for manipulation.

**Note on `author.subplebbit` trust limitations**: While `author.subplebbit.*` fields are generated by the subplebbit (not the user), a malicious subplebbit owner can still manipulate values like `postScore` and `replyScore`. The count-based karma approach mitigates this by giving each subplebbit exactly one vote regardless of karma magnitude. Additionally, an author's `author.subplebbit` data only exists after they sign and publish a comment to that subplebbit—this means attackers cannot create thousands of subplebbits to manipulate _someone else's_ reputation, since the target must actively participate in each sub.

**Note on timestamp trust**: `author.subplebbit.firstCommentTimestamp` and `comment.timestamp` are **NOT TRUSTED** for account age calculation. A malicious subplebbit owner can fabricate `firstCommentTimestamp`, and since subplebbits only validate that `comment.timestamp` is "recent", an owner can backdate their own comments. We cannot detect subplebbit ownership at the protocol level (author signer keys are separate from subplebbit keys). Therefore, account age is calculated **only from server-generated timestamps** (when our system first observed the author).

## Author Identity Tracking

**Important**: `author.address` is NOT used for identity tracking.

The `author.address` field can be either:

- A b58-encoded IPNS address (cryptographically tied to the author's key)
- A domain name (not cryptographically tied to the author)

Since `author.address` can be a domain that the author controls but doesn't cryptographically prove ownership of, we use the **signature's public key** (`publication.signature.publicKey`) for all identity-related tracking:

- Velocity tracking (how fast an author is posting)
- Karma aggregation (author's reputation across subplebbits)
- Account age (first seen timestamp)
- Content similarity detection (same author vs. different authors)
- Link spam detection (same author vs. coordinated campaigns)

The Ed25519 public key in the signature is the cryptographic identifier that truly identifies the author across all their publications.

## Data Sources

Risk factors query data from two separate database table sets:

1. **Engine tables** (`comments`, `votes`, `commentEdits`, `commentModerations`): Populated by `/evaluate` endpoint when publications are submitted for spam detection
2. **Indexer tables** (`indexed_comments_ipfs`, `indexed_comments_update`, `modqueue_*`): Populated by the background indexer which crawls subplebbits

The `CombinedDataService` queries both sources and combines data using factor-specific strategies:

| Factor                  | Combination Strategy                                            |
| ----------------------- | --------------------------------------------------------------- |
| Account Age             | MIN of server-generated timestamps only (receivedAt, fetchedAt) |
| Karma                   | Per-subplebbit, use LATEST entry from either source             |
| Velocity                | SUM (combine counts from both sources)                          |
| Content/Link Similarity | UNION (query both sources)                                      |
| Network factors         | Indexer only (ban history, modqueue rejection, removal)         |

This approach provides:

- **Broader coverage**: Authors may have history in indexer even if they've never used this spam detection server
- **Fresher data**: Engine data is real-time from `/evaluate` calls
- **More accurate**: Uses the most relevant data for each factor type

## Risk Factors

### 1. Account Age (Weight: 12% without IP, 8% with IP)

Evaluates how long the author has been known to our system, using **only server-generated timestamps**:

1. `receivedAt` from engine database (when our server received the publication)
2. `fetchedAt` from indexer database (when our indexer fetched the comment)

The oldest timestamp from either source is used.

**SECURITY**: We do **NOT** trust:

- `author.subplebbit.firstCommentTimestamp` - can be fabricated by malicious subplebbit owners
- `comment.timestamp` - subplebbit owners can backdate their own comments (subplebbits only validate timestamps are "recent", which owners can bypass)

We cannot detect subplebbit ownership at the protocol level (author signer keys are separate from subplebbit keys), so we cannot filter "owned" vs "external" subplebbits. The only secure approach is to trust only our own server-generated timestamps.

**Tradeoff**: Account age reflects how long the author has been known to our system, not their actual Plebbit history. This is acceptable for security.

| Account Age | Risk Score | Description                      |
| ----------- | ---------- | -------------------------------- |
| > 365 days  | 0.10       | Very established, highly trusted |
| > 90 days   | 0.20       | Established account              |
| > 30 days   | 0.35       | Moderately established           |
| > 7 days    | 0.50       | Some history                     |
| > 1 day     | 0.70       | New account                      |
| < 1 day     | 0.85       | Very new account                 |
| No history  | 1.0        | No history in our system         |

**Rationale**: Older accounts (as observed by our system) have demonstrated sustained, non-malicious behavior over time.

### 2. Karma Score (Weight: 10% without IP, 6% with IP)

Evaluates the author's reputation using a **count-based approach** that is resistant to collusion attacks.

Instead of using raw karma values (which can be manipulated by colluding subplebbits), we count how many subplebbits the author has positive vs negative karma in. Each subplebbit gets exactly **1 vote** regardless of karma magnitude.

**Why count-based?**

- **Collusion resistance**: A few hostile subs giving massive negative karma can't tank an author's score if they have good standing elsewhere
- **Sybil resistance**: Inflated positive karma from friendly subs matters less when you're just counting "how many subs trust this author"
- **Democratic**: Each sub gets equal weight in the reputation signal

**Data sources:**

- **Current subplebbit**: From `author.subplebbit` (TRUSTED) in the challenge request
- **Other subplebbits**: Aggregated from combined engine + indexer data, using the **latest** entry per subplebbit

**Counting logic:**

- Positive sub: `postScore + replyScore > 0` → +1 positive vote
- Negative sub: `postScore + replyScore < 0` → +1 negative vote
- Zero karma: Doesn't count either way
- Net count = (positive subs) - (negative subs)

| Net Sub Count | Risk Score | Description                      |
| ------------- | ---------- | -------------------------------- |
| >= +5         | 0.10       | Widely trusted across network    |
| +3 to +4      | 0.20       | Trusted in multiple communities  |
| +1 to +2      | 0.35       | Generally positive standing      |
| 0             | 0.50       | Mixed/balanced reputation        |
| -1 to -2      | 0.65       | Some concerns                    |
| -3 to -4      | 0.80       | Multiple communities flag issues |
| <= -5         | 0.90       | Widely mistrusted                |
| No data       | 0.60       | Unknown author (slight negative) |

**Example - Collusion resistance:**

An author has:

- +10 karma in sub-a.eth (1 positive vote)
- +20 karma in sub-b.eth (1 positive vote)
- -1000 karma in hostile-sub.eth (1 negative vote)

Net = 2 - 1 = +1 → Risk score 0.35 (generally positive)

The hostile sub's massive negative karma only counts as 1 negative vote, not enough to override the author's good standing in other communities.

**Rationale**: This approach asks "How many independent communities vouch for this author?" which is a more robust signal than raw karma sums that can be gamed by a single bad actor.

**Mitigation - Domain-only karma**: To prevent self-promotion attacks, only karma from **domain-addressed subplebbits** is counted. IPNS addresses (like `12D3KooW...`) are free to create, making them vulnerable to sybil attacks. Domain addresses (like `example.eth`, `example.sol`, `example.com`) cost money to acquire, creating an economic barrier that makes mass subplebbit creation impractical. Additionally, the `/evaluate` endpoint only accepts requests from domain-addressed subplebbits that can be resolved via plebbit-js.

### 3. Comment Content/Title Risk (Weight: 14% without IP, 10% with IP)

Analyzes comment content and title for spam indicators by querying both engine and indexer databases for similar past publications. **Only applies to comments (posts and replies)** - returns neutral score (0.5) for other publication types.

**Similarity detection uses:**

1. SQL substring matching (LIKE) to find candidate matches
2. Jaccard similarity on word sets to calculate actual similarity (threshold: 60%)

**Note**: Results from both engine and indexer tables are combined to detect cross-subplebbit spam patterns.

| Indicator                                      | Score Impact | Description                            |
| ---------------------------------------------- | ------------ | -------------------------------------- |
| **Same Author - Content Duplicates**           |              |                                        |
| 5+ duplicate comments from same author in 24h  | +0.35        | Heavy self-spamming                    |
| 3-4 duplicate comments from same author in 24h | +0.25        | Moderate self-spamming                 |
| 1-2 duplicate comments from same author in 24h | +0.15        | Possible duplicate posting             |
| **Same Author - Similar Content**              |              |                                        |
| 3+ similar comments from same author in 24h    | +0.20        | Similar content spamming               |
| 1-2 similar comments from same author in 24h   | +0.10        | Possible template spam                 |
| **Other Authors - Content Duplicates**         |              |                                        |
| 5+ identical comments from other authors       | +0.40        | Coordinated spam campaign              |
| 2-4 identical comments from other authors      | +0.25        | Possible coordinated activity          |
| 1 identical comment from another author        | +0.10        | Content seen from another author       |
| **Other Authors - Similar Content**            |              |                                        |
| 3+ similar comments from other authors         | +0.20        | Similar content from multiple accounts |
| 1-2 similar comments from other authors        | +0.08        | Similar content seen elsewhere         |
| **Same Author - Title Duplicates**             |              |                                        |
| 3+ posts with same title from author in 24h    | +0.30        | Title spam                             |
| 1-2 posts with same title from author in 24h   | +0.15        | Possible duplicate posting             |
| **Same Author - Similar Titles**               |              |                                        |
| 2+ posts with similar title from author in 24h | +0.15        | Similar title spamming                 |
| **Other Authors - Title Duplicates**           |              |                                        |
| 3+ posts with same title from other authors    | +0.25        | Coordinated title spam                 |
| 1-2 posts with same title from another author  | +0.10        | Title seen from another author         |
| **Other Authors - Similar Titles**             |              |                                        |
| 2+ posts with similar title from other authors | +0.10        | Similar titles from multiple accounts  |
| **Static Content Analysis**                    |              |                                        |
| 5+ URLs in content                             | +0.15        | Excessive link dropping                |
| 3-4 URLs in content                            | +0.08        | Elevated link count                    |
| Excessive capitalization (>50% caps)           | +0.08        | SHOUTING (spam indicator)              |
| Repetitive patterns (repeated chars/words)     | +0.10        | Bot-like behavior                      |

**Note**: The base score for comments starts at 0.2 (low risk). Non-comment publications receive a neutral score of 0.5.

### 4. Comment URL/Link Risk (Weight: 12% without IP, 10% with IP)

Analyzes URLs from multiple sources in comments for spam indicators by querying both engine and indexer databases. **Only applies to comments (posts and replies)** - returns neutral score (0.5) for other publication types.

**URL Sources:**

- `comment.link` - dedicated link field for link posts
- `comment.content` - URLs embedded in post/reply content
- `comment.title` - URLs in post titles

All URLs from these sources are extracted, normalized, and analyzed for spam patterns.

Link counts from both sources are **summed** to detect cross-subplebbit link spam campaigns.

**No Fixed Time Window:**

Unlike some spam detection systems that only look at the last 24 hours, this factor analyzes the **entire historical record** of URL patterns. The key signal for distinguishing spam from organic behavior is **time clustering** - how closely together posts are made, not an arbitrary cutoff.

| Indicator                                          | Score Impact   | Description                                |
| -------------------------------------------------- | -------------- | ------------------------------------------ |
| **Same Author - Duplicate Links**                  |                |                                            |
| 5+ posts with same URL from author                 | +0.40          | Heavy link spam                            |
| 3-4 posts with same URL from author                | +0.25          | Moderate link spam                         |
| 1-2 posts with same URL from author                | +0.15          | Possible duplicate posting                 |
| **Other Authors - Duplicate Links (Coordinated)**  |                |                                            |
| 10+ posts with same URL from other authors         | +0.50          | Likely coordinated spam campaign           |
| 5-9 posts with same URL from other authors         | +0.35          | Possible coordinated spam                  |
| 2-4 posts with same URL from other authors         | +0.20          | URL seen from multiple authors             |
| 1 post with same URL from another author           | +0.10          | URL seen from another author               |
| **Domain Spam (Same Author)**                      |                |                                            |
| 10+ links to same domain from author               | +0.25          | Domain-focused spam                        |
| 5-9 links to same domain from author               | +0.15          | Elevated domain promotion                  |
| **Similar URL Detection (Prefix Matching)**        |                |                                            |
| 3+ similar URLs from author (clustered)            | +0.25 to +0.65 | URL variation spam (see time clustering)   |
| 3+ similar URLs from author (spread out)           | +0.10 to +0.20 | Lower risk if spread over time             |
| 5+ similar URLs from 3+ other authors (clustered)  | +0.30 to +0.60 | Coordinated campaign (see time clustering) |
| 5+ similar URLs from 3+ other authors (spread out) | +0.15          | Organic sharing pattern                    |
| **Suspicious URL Patterns**                        |                |                                            |
| Uses IP address instead of domain                  | +0.20          | Suspicious direct IP link                  |

**URL Similarity Detection:**

To catch spammers who slightly modify URLs (e.g., changing query parameters or referral codes), we extract a **URL prefix** consisting of `domain/path1/path2` (first two path segments). URLs with the same prefix are considered "similar."

**Example:** `https://spam.com/promo/deal?ref=abc` and `https://spam.com/promo/deal?ref=xyz` both have prefix `spam.com/promo/deal` and would be flagged as similar.

**Time Clustering Analysis:**

Time clustering is used to distinguish coordinated spam bursts from organic sharing that happens over days/weeks/months. We analyze the **standard deviation** of posting timestamps (using `publication.timestamp`) to measure how clustered posts are:

| Time Clustering (stddev) | Additional Risk | Description                                |
| ------------------------ | --------------- | ------------------------------------------ |
| < 1 hour                 | +0.30           | Very tight clustering - likely coordinated |
| 1-3 hours                | +0.20           | Moderate clustering - suspicious           |
| 3-6 hours                | +0.10           | Some clustering                            |
| > 6 hours                | +0.00           | Spread out - likely organic sharing        |

**Time clustering is applied to both same-author and cross-author URL detection:**

- **Same-author**: Rapid-fire posting of similar URLs gets higher risk than occasional reposting
- **Cross-author**: Multiple authors posting similar URLs within a short time indicates coordination

**Example - Cross-author:** 5 posts with the same URL prefix from 5 different authors:

- Posted within 10 minutes of each other → stddev ≈ 3 minutes → base +0.30, clustering +0.30 = +0.60 total risk
- Posted over 20 hours → stddev ≈ 7 hours → +0.15 risk (spread out, likely organic)

**Example - Same-author:** An author posts 5 similar URLs:

- All within 30 minutes → stddev ≈ 10 minutes → base +0.35, clustering +0.30 = +0.65 total risk
- Spread over 2 weeks → stddev > 24 hours → +0.20 risk (occasional sharing, not spam burst)

**Similarity Allowlist:**

Popular platforms where URL paths naturally vary (different content, not spam variations) are **excluded from similarity detection** but still checked for exact URL matches:

- Social media: x.com, twitter.com, youtube.com, youtu.be, reddit.com, facebook.com, instagram.com, tiktok.com, linkedin.com
- Developer platforms: github.com, gitlab.com, stackoverflow.com
- News/content: medium.com, substack.com
- Crypto block explorers: etherscan.io, arbiscan.io, basescan.org, bscscan.com, polygonscan.com, ftmscan.com, snowtrace.io, avascan.info

**Note**: The base score for comments with URLs starts at 0.2 (low risk). Comments without URLs receive a score of 0.2 (positive signal - no URLs is good). Non-comment publications receive a neutral score of 0.5. URL normalization removes tracking parameters (utm\_\*, fbclid, etc.) before comparison.

### 5. Velocity Risk (Weight: 10% without IP, 8% with IP)

Measures how frequently an author is publishing to detect burst spam behavior. Queries both engine and indexer databases to count publications by the author's **signature public key** in the last hour and last 24 hours. Counts from both sources are **summed** to capture total network-wide activity.

**Note**: Indexer only tracks posts and replies. Votes, edits, and moderations are counted from engine data only.

The velocity risk score is the **maximum** of three checks:

1. **Per-type velocity**: Publications of the current type vs type-specific thresholds
2. **Aggregate velocity**: Total publications across ALL types vs aggregate thresholds
3. **Cross-type penalty**: If another publication type has higher velocity, blend 50% of that risk

#### Per-Type Thresholds

Different publication types have different acceptable rates:

**Post thresholds (comments without parentCid):**

| Posts/Hour | Risk Score | Description          |
| ---------- | ---------- | -------------------- |
| 0-2        | 0.10       | Normal posting rate  |
| 3-5        | 0.40       | Elevated rate        |
| 6-8        | 0.70       | Suspicious rate      |
| 12+        | 0.95       | Likely automated/bot |

**Reply thresholds (comments with parentCid):**

| Replies/Hour | Risk Score | Description          |
| ------------ | ---------- | -------------------- |
| 0-5          | 0.10       | Normal posting rate  |
| 6-10         | 0.40       | Elevated rate        |
| 11-15        | 0.70       | Suspicious rate      |
| 25+          | 0.95       | Likely automated/bot |

**Vote thresholds:**

| Votes/Hour | Risk Score | Description          |
| ---------- | ---------- | -------------------- |
| 0-20       | 0.10       | Normal voting rate   |
| 21-40      | 0.40       | Elevated rate        |
| 41-60      | 0.70       | Suspicious rate      |
| 100+       | 0.95       | Likely automated/bot |

**Comment edit thresholds:**

| Edits/Hour | Risk Score | Description          |
| ---------- | ---------- | -------------------- |
| 0-3        | 0.10       | Normal editing rate  |
| 4-5        | 0.40       | Elevated rate        |
| 6-10       | 0.70       | Suspicious rate      |
| 15+        | 0.95       | Likely automated/bot |

**Comment moderation thresholds:**

| Moderations/Hour | Risk Score | Description            |
| ---------------- | ---------- | ---------------------- |
| 0-5              | 0.10       | Normal moderation rate |
| 6-10             | 0.40       | Elevated rate          |
| 11-15            | 0.70       | Suspicious rate        |
| 25+              | 0.95       | Likely automated/bot   |

#### Aggregate Velocity Thresholds

Tracks total publications across ALL types combined. This catches authors who spread activity across multiple types to stay under individual thresholds.

| Total Publications/Hour | Risk Score | Description          |
| ----------------------- | ---------- | -------------------- |
| 0-25                    | 0.10       | Normal activity      |
| 26-50                   | 0.40       | Elevated activity    |
| 51-80                   | 0.70       | Suspicious activity  |
| 150+                    | 0.95       | Likely automated/bot |

**Example**: An author with 5 posts + 10 replies + 40 votes + 5 edits + 5 moderations = 65 total/hour would be flagged as SUSPICIOUS (0.70) even if each individual type is within normal limits.

#### Cross-Type Velocity Penalty

When evaluating a publication, if another publication type has higher velocity risk, 50% of the difference is blended into the current type's score.

**Formula**: `penalizedScore = currentScore + (otherMaxScore - currentScore) × 0.5`

**Example**: An author submitting a new post (1 post/hr = NORMAL 0.10) but has 150 votes/hr (BOT_LIKE 0.95):

- Per-type post score: 0.10
- Vote velocity score: 0.95
- Cross-type penalty: `0.10 + (0.95 - 0.10) × 0.5 = 0.525`

This ensures that suspicious behavior in one publication type affects the risk assessment of other types.

#### Effective Rate Calculation

The effective rate for each check is the maximum of:

- Publications of that type in the last hour
- Average publications per hour over the last 24 hours

**Note**: Subplebbit edits are not tracked for velocity as they are administrative actions.

**Caveat - Replay attack vulnerability**: Currently, a malicious subplebbit could repeatedly call `/evaluate` with the same publication (different session IDs) to artificially inflate an author's velocity count, making them appear to be spamming. The fix is to add a uniqueness constraint on `publication.signature.signature` for all database insertions under `/evaluate`, so duplicate publications are ignored. Until this is implemented, velocity counts from the engine database may be manipulated.

### 6. Wallet Velocity Risk (Weight: 14% without IP, 14% with IP)

Tracks publication velocity by wallet address from `author.wallets`. Detects coordinated spam from users who share the same wallet-verified identity (e.g., mintpass NFT holders).

This factor uses publication-type-specific thresholds since different actions have different natural rates.

**Post thresholds (comments without parentCid):**

| Posts/Hour | Risk Score | Description          |
| ---------- | ---------- | -------------------- |
| 0-2        | 0.10       | Normal posting rate  |
| 3-5        | 0.40       | Elevated rate        |
| 6-8        | 0.70       | Suspicious rate      |
| 12+        | 0.95       | Likely automated/bot |

**Reply thresholds (comments with parentCid):**

| Replies/Hour | Risk Score | Description          |
| ------------ | ---------- | -------------------- |
| 0-5          | 0.10       | Normal posting rate  |
| 6-10         | 0.40       | Elevated rate        |
| 11-15        | 0.70       | Suspicious rate      |
| 25+          | 0.95       | Likely automated/bot |

**Vote thresholds:**

| Votes/Hour | Risk Score | Description          |
| ---------- | ---------- | -------------------- |
| 0-20       | 0.10       | Normal voting rate   |
| 21-40      | 0.40       | Elevated rate        |
| 41-60      | 0.70       | Suspicious rate      |
| 100+       | 0.95       | Likely automated/bot |

**Comment edit thresholds:**

| Edits/Hour | Risk Score | Description          |
| ---------- | ---------- | -------------------- |
| 0-3        | 0.10       | Normal editing rate  |
| 4-5        | 0.40       | Elevated rate        |
| 6-10       | 0.70       | Suspicious rate      |
| 15+        | 0.95       | Likely automated/bot |

**Note**: If an author has multiple wallets, the factor uses the highest velocity among all wallets. If no wallets are linked to the author, this factor is skipped (weight=0).

### 7. IP Risk (Weight: 0% without IP, 20% with IP)

When available (after iframe access), evaluates the author's IP address characteristics.

| IP Type     | Risk Score | Description           |
| ----------- | ---------- | --------------------- |
| Residential | 0.20       | Normal user IP        |
| Datacenter  | 0.70       | Often used for bots   |
| VPN         | 0.75       | Anonymizing service   |
| Proxy       | 0.85       | Anonymizing service   |
| Tor         | 0.95       | Highest anonymization |

**Note**: IP intelligence is best-effort and can have false positives. Use for informational purposes and rejection decisions only, not for auto-approval.

### 8. Network Ban History (Weight: 10% without IP, 8% with IP)

Evaluates the author's ban history across all indexed subplebbits. Authors banned from multiple communities are higher risk.

This factor uses data collected by the indexer, which:

- Subscribes to subplebbits discovered via the `/evaluate` API or `author.previousCommentCid` chains
- Tracks `CommentUpdate.author.subplebbit.banExpiresAt` to detect bans
- Aggregates ban data across all indexed subplebbits

| Bans Across Network | Risk Score | Description                    |
| ------------------- | ---------- | ------------------------------ |
| 0 bans              | 0.00       | No ban history                 |
| 1 ban               | 0.40       | Banned from one sub            |
| 2 bans              | 0.60       | Banned from multiple subs      |
| 3+ bans             | 0.85       | Serial ban evasion (high risk) |

**Rationale**: Authors banned from multiple subplebbits have a pattern of problematic behavior.

### 9. ModQueue Rejection Rate (Weight: 6% without IP, 4% with IP)

Evaluates what percentage of the author's modQueue submissions were rejected.

The indexer tracks `subplebbit.modQueue.pendingApproval` entries and detects resolution by:

- Checking if the comment appears in regular pages (accepted)
- Checking if a full `CommentUpdate` can be fetched (accepted)
- If neither, the submission was rejected

| Rejection Rate | Risk Score | Description                   |
| -------------- | ---------- | ----------------------------- |
| No data        | 0.50       | Neutral (no modQueue history) |
| 0-10%          | 0.10       | Consistently approved         |
| 10-30%         | 0.30       | Mostly approved               |
| 30-50%         | 0.50       | Mixed history                 |
| 50-70%         | 0.70       | Frequently rejected           |
| 70%+           | 0.90       | Usually rejected (high risk)  |

**Rationale**: Authors whose submissions are frequently rejected by moderators are more likely to be spamming.

### 10. Network Removal Rate (Weight: 8% without IP, 8% with IP)

Evaluates what percentage of the author's comments have been removed across all indexed subplebbits.

This includes:

- `CommentUpdate.removed = true` (mod removal)
- `CommentUpdate.approved = false` (disapproved)
- `CommentUpdate` fetch failures (likely purged/banned)

| Removal Rate | Risk Score | Description                  |
| ------------ | ---------- | ---------------------------- |
| No data      | 0.50       | Neutral (no indexed history) |
| 0-5%         | 0.10       | Rarely removed               |
| 5-15%        | 0.30       | Occasionally removed         |
| 15-30%       | 0.50       | Moderate removal rate        |
| 30-50%       | 0.70       | Frequently removed           |
| 50%+         | 0.90       | Mostly removed (high risk)   |

**Rationale**: Authors whose content is frequently removed are likely posting inappropriate content.

## Weight Distribution

Weights are redistributed based on whether IP information is available:

| Factor                     | Without IP | With IP  |
| -------------------------- | ---------- | -------- |
| Comment Content/Title Risk | 14%        | 10%      |
| Comment URL/Link Risk      | 12%        | 10%      |
| Velocity Risk              | 10%        | 8%       |
| Account Age                | 14%        | 10%      |
| Karma Score                | 12%        | 8%       |
| Wallet Velocity            | 14%        | 14%      |
| IP Risk                    | 0%         | 20%      |
| Network Ban History        | 10%        | 8%       |
| ModQueue Rejection Rate    | 6%         | 4%       |
| Network Removal Rate       | 8%         | 8%       |
| **Total**                  | **100%**   | **100%** |

## Score Calculation

The final score is computed as:

```
finalScore = Σ(factor.score × factor.weight) / Σ(factor.weight)
```

Each factor produces a score between 0.0 and 1.0, which is multiplied by its weight. The weighted scores are summed and normalized.

## Recommended Thresholds

These are suggested defaults for subplebbit configuration:

| Threshold             | Suggested Value | Action                                    |
| --------------------- | --------------- | ----------------------------------------- |
| `autoAcceptThreshold` | 0.2             | Auto-accept publications below this score |
| `autoRejectThreshold` | 0.8             | Auto-reject publications above this score |

Publications between these thresholds trigger a challenge (e.g., CAPTCHA).

## Worked Examples

_Note: Update these examples whenever risk scoring logic changes._

These examples show how the risk score is calculated for different scenarios. All examples assume no IP information is available (using the "Without IP" weight configuration).

### Example 1: New User Sharing a Link (First Post)

A brand new user making their first post with a link to their blog article.

```
comment.link: "https://blog.example.com/my-article"
comment.title: "I wrote about my experience with decentralized social media"
comment.content: "Check out my thoughts..."
```

| Factor             | Score                      | Weight | Weighted |
| ------------------ | -------------------------- | ------ | -------- |
| Account Age        | 1.0 (no history)           | 14%    | 0.140    |
| Karma              | 0.6 (no data)              | 12%    | 0.072    |
| Content Risk       | 0.2 (base, unique content) | 14%    | 0.028    |
| URL Risk           | 0.2 (base, first time URL) | 12%    | 0.024    |
| Velocity           | 0.1 (1 post/hr, normal)    | 10%    | 0.010    |
| Wallet Velocity    | — (skipped, no wallet)     | 0%     | 0        |
| Ban History        | 0.0 (no bans)              | 10%    | 0        |
| ModQueue Rejection | 0.5 (no data)              | 6%     | 0.030    |
| Removal Rate       | 0.5 (no data)              | 8%     | 0.040    |

**Final Score: ~0.40** → Moderate risk, triggers CAPTCHA challenge

### Example 2: Established User, No URLs

A well-established user (90+ days, positive karma across 4 subs) posting a question without any links.

```
comment.link: null
comment.title: "Question about plebbit development"
comment.content: "Has anyone figured out how to run a subplebbit on a VPS?"
```

| Factor             | Score                        | Weight | Weighted |
| ------------------ | ---------------------------- | ------ | -------- |
| Account Age        | 0.2 (>90 days)               | 14%    | 0.028    |
| Karma              | 0.2 (+3 to +4 subs positive) | 12%    | 0.024    |
| Content Risk       | 0.2 (base, unique)           | 14%    | 0.028    |
| URL Risk           | 0.2 (no URLs - positive)     | 12%    | 0.024    |
| Velocity           | 0.1 (normal)                 | 10%    | 0.010    |
| Wallet Velocity    | — (skipped)                  | 0%     | 0        |
| Ban History        | 0.0                          | 10%    | 0        |
| ModQueue Rejection | 0.1 (0-10% rejected)         | 6%     | 0.006    |
| Removal Rate       | 0.1 (0-5% removed)           | 8%     | 0.008    |

**Final Score: ~0.15** → Low risk, auto-accepted

### Example 3: Affiliate Link Spammer

A new user posting the same affiliate link for the 6th time with spammy content.

```
comment.link: "https://sketchy.io/buy/crypto?ref=abc123"
comment.title: "FREE CRYPTO - Don't miss out!!!"
comment.content: "Click here for FREE money!!!"
```

| Factor             | Score                                                                     | Weight | Weighted |
| ------------------ | ------------------------------------------------------------------------- | ------ | -------- |
| Account Age        | 0.85 (<1 day old)                                                         | 14%    | 0.119    |
| Karma              | 0.6 (no data)                                                             | 12%    | 0.072    |
| Content Risk       | 0.53 (base 0.2 + caps 0.08 + 3 duplicates 0.25)                           | 14%    | 0.074    |
| URL Risk           | 0.85 (base 0.2 + 5+ same URL 0.4 + 5-9 domain 0.15 + time clustering 0.1) | 12%    | 0.102    |
| Velocity           | 0.4 (3-5 posts/hr)                                                        | 10%    | 0.040    |
| Wallet Velocity    | — (skipped)                                                               | 0%     | 0        |
| Ban History        | 0.0                                                                       | 10%    | 0        |
| ModQueue Rejection | 0.5 (no data)                                                             | 6%     | 0.030    |
| Removal Rate       | 0.5 (no data)                                                             | 8%     | 0.040    |

**Final Score: ~0.55** → Moderate-high risk, CAPTCHA required

### Example 4: Coordinated Spam Campaign

Multiple new accounts posting the same scam URL within minutes of each other. This is one of the spam accounts.

```
comment.link: "https://scam-token.io/presale"
comment.title: "Amazing new token presale!"
comment.content: "Get in early on this opportunity!"
```

10 other authors posted the same URL and similar content within the last hour.

| Factor             | Score                                                      | Weight | Weighted |
| ------------------ | ---------------------------------------------------------- | ------ | -------- |
| Account Age        | 1.0 (no history)                                           | 14%    | 0.140    |
| Karma              | 0.6 (no data)                                              | 12%    | 0.072    |
| Content Risk       | 0.6 (base 0.2 + 5+ identical from others 0.4)              | 14%    | 0.084    |
| URL Risk           | 1.0 (base 0.2 + 10+ coordinated 0.5 + time clustering 0.3) | 12%    | 0.120    |
| Velocity           | 0.1 (first post)                                           | 10%    | 0.010    |
| Wallet Velocity    | — (skipped)                                                | 0%     | 0        |
| Ban History        | 0.0                                                        | 10%    | 0        |
| ModQueue Rejection | 0.5 (no data)                                              | 6%     | 0.030    |
| Removal Rate       | 0.5 (no data)                                              | 8%     | 0.040    |

**Final Score: ~0.58** → Moderate-high risk, CAPTCHA required

### Example 5: URL Variation Spammer (Time-Clustered)

An author posting similar URLs with different referral codes, all within 30 minutes.

```
comment.link: "https://spam.com/promo/deal?ref=user99"
comment.title: "Great deal here #99"
comment.content: null
```

Same author has posted 5 similar URLs (`spam.com/promo/deal?ref=user1`, etc.) within 30 minutes.

| Factor             | Score                                                        | Weight | Weighted |
| ------------------ | ------------------------------------------------------------ | ------ | -------- |
| Account Age        | 0.85 (<1 day old)                                            | 14%    | 0.119    |
| Karma              | 0.6 (no data)                                                | 12%    | 0.072    |
| Content Risk       | 0.35 (base 0.2 + similar titles 0.15)                        | 14%    | 0.049    |
| URL Risk           | 0.85 (base 0.2 + 5+ similar clustered 0.35 + time bonus 0.3) | 12%    | 0.102    |
| Velocity           | 0.7 (6-8 posts/hr)                                           | 10%    | 0.070    |
| Wallet Velocity    | — (skipped)                                                  | 0%     | 0        |
| Ban History        | 0.4 (1 ban from another sub)                                 | 10%    | 0.040    |
| ModQueue Rejection | 0.5 (no data)                                                | 6%     | 0.030    |
| Removal Rate       | 0.5 (no data)                                                | 8%     | 0.040    |

**Final Score: ~0.60** → Moderate-high risk, CAPTCHA required

### Example 6: Repeat Offender (Banned, High Removal Rate)

A known bad actor with multiple bans and high removal rate posting suspicious content.

```
comment.link: "https://192.168.1.100/download.exe"
comment.title: "FREE SOFTWARE DOWNLOAD NOW"
comment.content: "CLICK HERE NOW!!! DON'T MISS OUT!!!"
```

| Factor             | Score                                                              | Weight | Weighted |
| ------------------ | ------------------------------------------------------------------ | ------ | -------- |
| Account Age        | 0.7 (>1 day, <7 days)                                              | 14%    | 0.098    |
| Karma              | 0.8 (-3 to -4 subs negative)                                       | 12%    | 0.096    |
| Content Risk       | 0.58 (base 0.2 + caps 0.08 + repetitive 0.1 + duplicate title 0.2) | 14%    | 0.081    |
| URL Risk           | 0.4 (base 0.2 + IP address 0.2)                                    | 12%    | 0.048    |
| Velocity           | 0.4 (elevated)                                                     | 10%    | 0.040    |
| Wallet Velocity    | — (skipped)                                                        | 0%     | 0        |
| Ban History        | 0.85 (3+ bans)                                                     | 10%    | 0.085    |
| ModQueue Rejection | 0.9 (70%+ rejected)                                                | 6%     | 0.054    |
| Removal Rate       | 0.9 (50%+ removed)                                                 | 8%     | 0.072    |

**Final Score: ~0.69** → High risk, close to auto-reject threshold

### Summary Table

| Scenario                               | Final Score | Action               |
| -------------------------------------- | ----------- | -------------------- |
| New user, first post with link         | ~0.40       | CAPTCHA              |
| Established user, no URLs              | ~0.15       | Auto-accept          |
| Affiliate link spammer                 | ~0.55       | CAPTCHA              |
| Coordinated campaign (10+ authors)     | ~0.58       | CAPTCHA              |
| URL variation spam (time-clustered)    | ~0.60       | CAPTCHA              |
| Repeat offender (banned, high removal) | ~0.69       | Close to auto-reject |

## Limitations

1. **IP Intelligence Accuracy**: VPN/proxy detection is imperfect. Residential IPs can be misclassified.

2. **New Subplebbit Limitation**: For new subplebbits, `author.subplebbit` data may be empty for all users initially.

3. **Content Similarity Scope**: Uses word-level Jaccard similarity (60% threshold). May miss semantically similar content that uses different words. Substring matching helps catch some variations but sophisticated paraphrasing may evade detection.

4. **Comment-Only Content Analysis**: Content/title similarity analysis only applies to comments (posts and replies). Other publication types (votes, edits, moderations) receive a neutral score for this factor.

## Future Improvements

- Challenge completion history tracking
- Machine learning-based content analysis
- Moderation action history integration
