# Risk Scoring System

This document explains how EasyCommunitySpamBlocker calculates risk scores for publications.

## Overview

The risk score is a value between 0.0 and 1.0 that indicates the likelihood a publication is spam or malicious:

- **0.0 - 0.3**: Low risk (likely legitimate)
- **0.3 - 0.7**: Moderate risk (may require verification)
- **0.7 - 1.0**: High risk (likely spam/malicious)

The score is calculated as a weighted combination of multiple factors, each analyzing different aspects of the publication and its author.

## Trust Model

**Important**: Not all author data can be trusted equally.

- `author.subplebbit.*` fields are **PARTIALLY TRUSTED** - they are generated by the subplebbit, but subplebbit owners can manipulate them
- All other `author.*` fields are **UNTRUSTED** - they are provided by the user and can be faked

**Note on `author.wallets` and `author.avatar`**: These fields contain internal signatures, but plebbit-js only validates them during specific subplebbit challenges (e.g., EVM contract call challenge). When a client loads a comment by CID, these signatures are NOT automatically verified. This spam detection engine does not validate these signatures itself, so these fields should be treated as **UNTRUSTED** for risk scoring purposes. The wallet velocity factor uses wallet addresses for tracking but does not rely on them as proof of identity.

The risk scoring system primarily relies on `author.subplebbit` data for reputation signals, with mitigations for manipulation.

**Note on `author.subplebbit` trust limitations**: While `author.subplebbit.*` fields are generated by the subplebbit (not the user), a malicious subplebbit owner can still manipulate values like `postScore` and `replyScore`. The count-based karma approach mitigates this by giving each subplebbit exactly one vote regardless of karma magnitude. Additionally, an author's `author.subplebbit` data only exists after they sign and publish a comment to that subplebbit—this means attackers cannot create thousands of subplebbits to manipulate _someone else's_ reputation, since the target must actively participate in each sub.

**Note on timestamp trust**: `author.subplebbit.firstCommentTimestamp` and `comment.timestamp` are **NOT TRUSTED** for account age calculation. A malicious subplebbit owner can fabricate `firstCommentTimestamp`, and since subplebbits only validate that `comment.timestamp` is "recent", an owner can backdate their own comments. We cannot detect subplebbit ownership at the protocol level (author signer keys are separate from subplebbit keys). Therefore, account age is calculated **only from server-generated timestamps** (when our system first observed the author).

## Author Identity Tracking

**Important**: `author.address` is NOT used for identity tracking.

The `author.address` field can be either:

- A b58-encoded IPNS address (cryptographically tied to the author's key)
- A domain name (not cryptographically tied to the author)

Since `author.address` can be a domain that the author controls but doesn't cryptographically prove ownership of, we use the **signature's public key** (`publication.signature.publicKey`) for all identity-related tracking:

- Velocity tracking (how fast an author is posting)
- Karma aggregation (author's reputation across subplebbits)
- Account age (first seen timestamp)
- Content similarity detection (same author vs. different authors)
- Link spam detection (same author vs. coordinated campaigns)

The Ed25519 public key in the signature is the cryptographic identifier that truly identifies the author across all their publications.

## Data Sources

Risk factors query data from two separate database table sets:

1. **Engine tables** (`comments`, `votes`, `commentEdits`, `commentModerations`): Populated by `/evaluate` endpoint when publications are submitted for spam detection
2. **Indexer tables** (`indexed_comments_ipfs`, `indexed_comments_update`, `modqueue_*`): Populated by the background indexer which crawls subplebbits

The `CombinedDataService` queries both sources and combines data using factor-specific strategies:

| Factor                  | Combination Strategy                                            |
| ----------------------- | --------------------------------------------------------------- |
| Account Age             | MIN of server-generated timestamps only (receivedAt, fetchedAt) |
| Karma                   | Per-subplebbit, use LATEST entry from either source             |
| Velocity                | SUM (combine counts from both sources)                          |
| Content/Link Similarity | UNION (query both sources)                                      |
| Network factors         | Indexer only (ban history, modqueue rejection, removal)         |

This approach provides:

- **Broader coverage**: Authors may have history in indexer even if they've never used this spam detection server
- **Fresher data**: Engine data is real-time from `/evaluate` calls
- **More accurate**: Uses the most relevant data for each factor type

## Risk Factors

### 1. Account Age (Weight: 12% without IP, 8% with IP)

Evaluates how long the author has been known to our system, using **only server-generated timestamps**:

1. `receivedAt` from engine database (when our server received the publication)
2. `fetchedAt` from indexer database (when our indexer fetched the comment)

The oldest timestamp from either source is used.

**SECURITY**: We do **NOT** trust:

- `author.subplebbit.firstCommentTimestamp` - can be fabricated by malicious subplebbit owners
- `comment.timestamp` - subplebbit owners can backdate their own comments (subplebbits only validate timestamps are "recent", which owners can bypass)

We cannot detect subplebbit ownership at the protocol level (author signer keys are separate from subplebbit keys), so we cannot filter "owned" vs "external" subplebbits. The only secure approach is to trust only our own server-generated timestamps.

**Tradeoff**: Account age reflects how long the author has been known to our system, not their actual Plebbit history. This is acceptable for security.

| Account Age | Risk Score | Description                      |
| ----------- | ---------- | -------------------------------- |
| > 365 days  | 0.10       | Very established, highly trusted |
| > 90 days   | 0.20       | Established account              |
| > 30 days   | 0.35       | Moderately established           |
| > 7 days    | 0.50       | Some history                     |
| > 1 day     | 0.70       | New account                      |
| < 1 day     | 0.85       | Very new account                 |
| No history  | 0.90       | No history in our system         |

**Rationale**: Older accounts (as observed by our system) have demonstrated sustained, non-malicious behavior over time.

### 2. Karma Score (Weight: 10% without IP, 6% with IP)

Evaluates the author's reputation using a **count-based approach** that is resistant to collusion attacks.

Instead of using raw karma values (which can be manipulated by colluding subplebbits), we count how many subplebbits the author has positive vs negative karma in. Each subplebbit gets exactly **1 vote** regardless of karma magnitude.

**Why count-based?**

- **Collusion resistance**: A few hostile subs giving massive negative karma can't tank an author's score if they have good standing elsewhere
- **Sybil resistance**: Inflated positive karma from friendly subs matters less when you're just counting "how many subs trust this author"
- **Democratic**: Each sub gets equal weight in the reputation signal

**Data sources:**

- **Current subplebbit**: From `author.subplebbit` (TRUSTED) in the challenge request
- **Other subplebbits**: Aggregated from combined engine + indexer data, using the **latest** entry per subplebbit

**Counting logic:**

- Positive sub: `postScore + replyScore > 0` → +1 positive vote
- Negative sub: `postScore + replyScore < 0` → +1 negative vote
- Zero karma: Doesn't count either way
- Net count = (positive subs) - (negative subs)

| Net Sub Count | Risk Score | Description                       |
| ------------- | ---------- | --------------------------------- |
| >= +5         | 0.10       | Widely trusted across network     |
| +3 to +4      | 0.20       | Trusted in multiple communities   |
| +1 to +2      | 0.35       | Generally positive standing       |
| 0             | 0.50       | Mixed/balanced reputation         |
| -1 to -2      | 0.65       | Some concerns                     |
| -3 to -4      | 0.80       | Multiple communities flag issues  |
| <= -5         | 0.90       | Widely mistrusted                 |
| No data       | 0.50       | Neutral (no karma data available) |

**Example - Collusion resistance:**

An author has:

- +10 karma in sub-a.eth (1 positive vote)
- +20 karma in sub-b.eth (1 positive vote)
- -1000 karma in hostile-sub.eth (1 negative vote)

Net = 2 - 1 = +1 → Risk score 0.35 (generally positive)

The hostile sub's massive negative karma only counts as 1 negative vote, not enough to override the author's good standing in other communities.

**Rationale**: This approach asks "How many independent communities vouch for this author?" which is a more robust signal than raw karma sums that can be gamed by a single bad actor.

**Mitigation - Domain-only karma**: To prevent self-promotion attacks, only karma from **domain-addressed subplebbits** is counted. IPNS addresses (like `12D3KooW...`) are free to create, making them vulnerable to sybil attacks. Domain addresses (like `example.eth`, `example.sol`, `example.com`) cost money to acquire, creating an economic barrier that makes mass subplebbit creation impractical. Additionally, the `/evaluate` endpoint only accepts requests from domain-addressed subplebbits that can be resolved via plebbit-js.

### 3. Comment Content/Title Risk (Weight: 14% without IP, 10% with IP)

Analyzes comment content and title for spam indicators by querying both engine and indexer databases for similar past publications. **Only applies to comments (posts and replies)** - returns neutral score (0.5) for other publication types.

**Similarity detection uses:**

1. SQL substring matching (LIKE) to find candidate matches
2. Jaccard similarity on word sets to calculate actual similarity (threshold: 60%)

**Note**: Results from both engine and indexer tables are combined to detect cross-subplebbit spam patterns.

| Indicator                                      | Score Impact | Description                            |
| ---------------------------------------------- | ------------ | -------------------------------------- |
| **Same Author - Content Duplicates**           |              |                                        |
| 5+ duplicate comments from same author in 24h  | +0.35        | Heavy self-spamming                    |
| 3-4 duplicate comments from same author in 24h | +0.25        | Moderate self-spamming                 |
| 1-2 duplicate comments from same author in 24h | +0.15        | Possible duplicate posting             |
| **Same Author - Similar Content**              |              |                                        |
| 3+ similar comments from same author in 24h    | +0.20        | Similar content spamming               |
| 1-2 similar comments from same author in 24h   | +0.10        | Possible template spam                 |
| **Other Authors - Content Duplicates**         |              |                                        |
| 5+ identical comments from other authors       | +0.40        | Coordinated spam campaign              |
| 2-4 identical comments from other authors      | +0.25        | Possible coordinated activity          |
| 1 identical comment from another author        | +0.10        | Content seen from another author       |
| **Other Authors - Similar Content**            |              |                                        |
| 3+ similar comments from other authors         | +0.20        | Similar content from multiple accounts |
| 1-2 similar comments from other authors        | +0.08        | Similar content seen elsewhere         |
| **Same Author - Title Duplicates**             |              |                                        |
| 3+ posts with same title from author in 24h    | +0.30        | Title spam                             |
| 1-2 posts with same title from author in 24h   | +0.15        | Possible duplicate posting             |
| **Same Author - Similar Titles**               |              |                                        |
| 2+ posts with similar title from author in 24h | +0.15        | Similar title spamming                 |
| **Other Authors - Title Duplicates**           |              |                                        |
| 3+ posts with same title from other authors    | +0.25        | Coordinated title spam                 |
| 1-2 posts with same title from another author  | +0.10        | Title seen from another author         |
| **Other Authors - Similar Titles**             |              |                                        |
| 2+ posts with similar title from other authors | +0.10        | Similar titles from multiple accounts  |
| **Static Content Analysis**                    |              |                                        |
| 5+ URLs in content                             | +0.15        | Excessive link dropping                |
| 3-4 URLs in content                            | +0.08        | Elevated link count                    |
| Excessive capitalization (>50% caps)           | +0.08        | SHOUTING (spam indicator)              |
| Repetitive patterns (repeated chars/words)     | +0.10        | Bot-like behavior                      |

**Note**: The base score for comments starts at 0.2 (low risk). Non-comment publications receive a neutral score of 0.5.

### 4. Comment URL/Link Risk (Weight: 12% without IP, 10% with IP)

Analyzes `comment.link` (the dedicated link field for link posts) for spam indicators by querying both engine and indexer databases. This is separate from URLs found in `comment.content`. **Only applies to comments (posts and replies) that have a link** - returns neutral score (0.5) for other publications or comments without links.

Link counts from both sources are **summed** to detect cross-subplebbit link spam campaigns.

| Indicator                                         | Score Impact | Description                      |
| ------------------------------------------------- | ------------ | -------------------------------- |
| **Same Author - Duplicate Links**                 |              |                                  |
| 5+ posts with same link from author in 24h        | +0.40        | Heavy link spam                  |
| 3-4 posts with same link from author in 24h       | +0.25        | Moderate link spam               |
| 1-2 posts with same link from author in 24h       | +0.15        | Possible duplicate posting       |
| **Other Authors - Duplicate Links (Coordinated)** |              |                                  |
| 10+ posts with same link from other authors       | +0.50        | Likely coordinated spam campaign |
| 5-9 posts with same link from other authors       | +0.35        | Possible coordinated spam        |
| 2-4 posts with same link from other authors       | +0.20        | Link seen from multiple authors  |
| 1 post with same link from another author         | +0.10        | Link seen from another author    |
| **Domain Spam (Same Author)**                     |              |                                  |
| 10+ links to same domain from author in 24h       | +0.25        | Domain-focused spam              |
| 5-9 links to same domain from author in 24h       | +0.15        | Elevated domain promotion        |
| **Suspicious URL Patterns**                       |              |                                  |
| Uses URL shortener (bit.ly, tinyurl, etc.)        | +0.15        | Link obfuscation                 |
| Uses IP address instead of domain                 | +0.20        | Suspicious direct IP link        |
| Unusually long URL (>500 chars)                   | +0.10        | Possible obfuscation             |
| Excessive query parameters (>5)                   | +0.05        | Possible tracking/affiliate link |
| Invalid URL format                                | +0.10        | Malformed link                   |

**Note**: The base score for comments with links starts at 0.2 (low risk). Non-comment publications or comments without links receive a neutral score of 0.5. URL normalization removes tracking parameters (utm\_\*, fbclid, etc.) before comparison.

### 5. Velocity Risk (Weight: 10% without IP, 8% with IP)

Measures how frequently an author is publishing to detect burst spam behavior. Queries both engine and indexer databases to count publications by the author's **signature public key** in the last hour and last 24 hours. Counts from both sources are **summed** to capture total network-wide activity.

**Note**: Indexer only tracks posts and replies. Votes, edits, and moderations are counted from engine data only.

The velocity risk score is the **maximum** of three checks:

1. **Per-type velocity**: Publications of the current type vs type-specific thresholds
2. **Aggregate velocity**: Total publications across ALL types vs aggregate thresholds
3. **Cross-type penalty**: If another publication type has higher velocity, blend 50% of that risk

#### Per-Type Thresholds

Different publication types have different acceptable rates:

**Post thresholds (comments without parentCid):**

| Posts/Hour | Risk Score | Description          |
| ---------- | ---------- | -------------------- |
| 0-2        | 0.10       | Normal posting rate  |
| 3-5        | 0.40       | Elevated rate        |
| 6-8        | 0.70       | Suspicious rate      |
| 12+        | 0.95       | Likely automated/bot |

**Reply thresholds (comments with parentCid):**

| Replies/Hour | Risk Score | Description          |
| ------------ | ---------- | -------------------- |
| 0-5          | 0.10       | Normal posting rate  |
| 6-10         | 0.40       | Elevated rate        |
| 11-15        | 0.70       | Suspicious rate      |
| 25+          | 0.95       | Likely automated/bot |

**Vote thresholds:**

| Votes/Hour | Risk Score | Description          |
| ---------- | ---------- | -------------------- |
| 0-20       | 0.10       | Normal voting rate   |
| 21-40      | 0.40       | Elevated rate        |
| 41-60      | 0.70       | Suspicious rate      |
| 100+       | 0.95       | Likely automated/bot |

**Comment edit thresholds:**

| Edits/Hour | Risk Score | Description          |
| ---------- | ---------- | -------------------- |
| 0-3        | 0.10       | Normal editing rate  |
| 4-5        | 0.40       | Elevated rate        |
| 6-10       | 0.70       | Suspicious rate      |
| 15+        | 0.95       | Likely automated/bot |

**Comment moderation thresholds:**

| Moderations/Hour | Risk Score | Description            |
| ---------------- | ---------- | ---------------------- |
| 0-5              | 0.10       | Normal moderation rate |
| 6-10             | 0.40       | Elevated rate          |
| 11-15            | 0.70       | Suspicious rate        |
| 25+              | 0.95       | Likely automated/bot   |

#### Aggregate Velocity Thresholds

Tracks total publications across ALL types combined. This catches authors who spread activity across multiple types to stay under individual thresholds.

| Total Publications/Hour | Risk Score | Description          |
| ----------------------- | ---------- | -------------------- |
| 0-25                    | 0.10       | Normal activity      |
| 26-50                   | 0.40       | Elevated activity    |
| 51-80                   | 0.70       | Suspicious activity  |
| 150+                    | 0.95       | Likely automated/bot |

**Example**: An author with 5 posts + 10 replies + 40 votes + 5 edits + 5 moderations = 65 total/hour would be flagged as SUSPICIOUS (0.70) even if each individual type is within normal limits.

#### Cross-Type Velocity Penalty

When evaluating a publication, if another publication type has higher velocity risk, 50% of the difference is blended into the current type's score.

**Formula**: `penalizedScore = currentScore + (otherMaxScore - currentScore) × 0.5`

**Example**: An author submitting a new post (1 post/hr = NORMAL 0.10) but has 150 votes/hr (BOT_LIKE 0.95):

- Per-type post score: 0.10
- Vote velocity score: 0.95
- Cross-type penalty: `0.10 + (0.95 - 0.10) × 0.5 = 0.525`

This ensures that suspicious behavior in one publication type affects the risk assessment of other types.

#### Effective Rate Calculation

The effective rate for each check is the maximum of:

- Publications of that type in the last hour
- Average publications per hour over the last 24 hours

**Note**: Subplebbit edits are not tracked for velocity as they are administrative actions.

**Caveat - Replay attack vulnerability**: Currently, a malicious subplebbit could repeatedly call `/evaluate` with the same publication (different session IDs) to artificially inflate an author's velocity count, making them appear to be spamming. The fix is to add a uniqueness constraint on `publication.signature.signature` for all database insertions under `/evaluate`, so duplicate publications are ignored. Until this is implemented, velocity counts from the engine database may be manipulated.

### 6. Wallet Velocity Risk (Weight: 14% without IP, 14% with IP)

Tracks publication velocity by wallet address from `author.wallets`. Detects coordinated spam from users who share the same wallet-verified identity (e.g., mintpass NFT holders).

This factor uses publication-type-specific thresholds since different actions have different natural rates.

**Post thresholds (comments without parentCid):**

| Posts/Hour | Risk Score | Description          |
| ---------- | ---------- | -------------------- |
| 0-2        | 0.10       | Normal posting rate  |
| 3-5        | 0.40       | Elevated rate        |
| 6-8        | 0.70       | Suspicious rate      |
| 12+        | 0.95       | Likely automated/bot |

**Reply thresholds (comments with parentCid):**

| Replies/Hour | Risk Score | Description          |
| ------------ | ---------- | -------------------- |
| 0-5          | 0.10       | Normal posting rate  |
| 6-10         | 0.40       | Elevated rate        |
| 11-15        | 0.70       | Suspicious rate      |
| 25+          | 0.95       | Likely automated/bot |

**Vote thresholds:**

| Votes/Hour | Risk Score | Description          |
| ---------- | ---------- | -------------------- |
| 0-20       | 0.10       | Normal voting rate   |
| 21-40      | 0.40       | Elevated rate        |
| 41-60      | 0.70       | Suspicious rate      |
| 100+       | 0.95       | Likely automated/bot |

**Comment edit thresholds:**

| Edits/Hour | Risk Score | Description          |
| ---------- | ---------- | -------------------- |
| 0-3        | 0.10       | Normal editing rate  |
| 4-5        | 0.40       | Elevated rate        |
| 6-10       | 0.70       | Suspicious rate      |
| 15+        | 0.95       | Likely automated/bot |

**Note**: If an author has multiple wallets, the factor uses the highest velocity among all wallets. If no wallets are linked to the author, this factor is skipped (weight=0).

### 7. IP Risk (Weight: 0% without IP, 20% with IP)

When available (after iframe access), evaluates the author's IP address characteristics.

| IP Type     | Risk Score | Description           |
| ----------- | ---------- | --------------------- |
| Residential | 0.20       | Normal user IP        |
| Datacenter  | 0.70       | Often used for bots   |
| VPN         | 0.75       | Anonymizing service   |
| Proxy       | 0.85       | Anonymizing service   |
| Tor         | 0.95       | Highest anonymization |

**Note**: IP intelligence is best-effort and can have false positives. Use for informational purposes and rejection decisions only, not for auto-approval.

### 8. Network Ban History (Weight: 8% without IP, 6% with IP)

Evaluates the author's ban history across all indexed subplebbits. Authors banned from multiple communities are higher risk.

This factor uses data collected by the indexer, which:

- Subscribes to subplebbits discovered via the `/evaluate` API or `author.previousCommentCid` chains
- Tracks `CommentUpdate.author.subplebbit.banExpiresAt` to detect bans
- Aggregates ban data across all indexed subplebbits

| Bans Across Network | Risk Score | Description                    |
| ------------------- | ---------- | ------------------------------ |
| 0 bans              | 0.00       | No ban history                 |
| 1 ban               | 0.40       | Banned from one sub            |
| 2 bans              | 0.60       | Banned from multiple subs      |
| 3+ bans             | 0.85       | Serial ban evasion (high risk) |

**Rationale**: Authors banned from multiple subplebbits have a pattern of problematic behavior.

### 9. ModQueue Rejection Rate (Weight: 8% without IP, 6% with IP)

Evaluates what percentage of the author's modQueue submissions were rejected.

The indexer tracks `subplebbit.modQueue.pendingApproval` entries and detects resolution by:

- Checking if the comment appears in regular pages (accepted)
- Checking if a full `CommentUpdate` can be fetched (accepted)
- If neither, the submission was rejected

| Rejection Rate | Risk Score | Description                   |
| -------------- | ---------- | ----------------------------- |
| No data        | 0.50       | Neutral (no modQueue history) |
| 0-10%          | 0.10       | Consistently approved         |
| 10-30%         | 0.30       | Mostly approved               |
| 30-50%         | 0.50       | Mixed history                 |
| 50-70%         | 0.70       | Frequently rejected           |
| 70%+           | 0.90       | Usually rejected (high risk)  |

**Rationale**: Authors whose submissions are frequently rejected by moderators are more likely to be spamming.

### 10. Network Removal Rate (Weight: 8% without IP, 8% with IP)

Evaluates what percentage of the author's comments have been removed across all indexed subplebbits.

This includes:

- `CommentUpdate.removed = true` (mod removal)
- `CommentUpdate.approved = false` (disapproved)
- `CommentUpdate` fetch failures (likely purged/banned)

| Removal Rate | Risk Score | Description                  |
| ------------ | ---------- | ---------------------------- |
| No data      | 0.50       | Neutral (no indexed history) |
| 0-5%         | 0.10       | Rarely removed               |
| 5-15%        | 0.30       | Occasionally removed         |
| 15-30%       | 0.50       | Moderate removal rate        |
| 30-50%       | 0.70       | Frequently removed           |
| 50%+         | 0.90       | Mostly removed (high risk)   |

**Rationale**: Authors whose content is frequently removed are likely posting inappropriate content.

## Weight Distribution

Weights are redistributed based on whether IP information is available:

| Factor                     | Without IP | With IP  |
| -------------------------- | ---------- | -------- |
| Comment Content/Title Risk | 14%        | 10%      |
| Comment URL/Link Risk      | 12%        | 10%      |
| Velocity Risk              | 10%        | 8%       |
| Account Age                | 14%        | 10%      |
| Karma Score                | 12%        | 8%       |
| Wallet Velocity            | 14%        | 14%      |
| IP Risk                    | 0%         | 20%      |
| Network Ban History        | 8%         | 6%       |
| ModQueue Rejection Rate    | 8%         | 6%       |
| Network Removal Rate       | 8%         | 8%       |
| **Total**                  | **100%**   | **100%** |

## Score Calculation

The final score is computed as:

```
finalScore = Σ(factor.score × factor.weight) / Σ(factor.weight)
```

Each factor produces a score between 0.0 and 1.0, which is multiplied by its weight. The weighted scores are summed and normalized.

## Recommended Thresholds

These are suggested defaults for subplebbit configuration:

| Threshold             | Suggested Value | Action                                    |
| --------------------- | --------------- | ----------------------------------------- |
| `autoAcceptThreshold` | 0.2             | Auto-accept publications below this score |
| `autoRejectThreshold` | 0.8             | Auto-reject publications above this score |

Publications between these thresholds trigger a challenge (e.g., CAPTCHA).

## Limitations

1. **IP Intelligence Accuracy**: VPN/proxy detection is imperfect. Residential IPs can be misclassified.

2. **New Subplebbit Limitation**: For new subplebbits, `author.subplebbit` data may be empty for all users initially.

3. **Content Similarity Scope**: Uses word-level Jaccard similarity (60% threshold). May miss semantically similar content that uses different words. Substring matching helps catch some variations but sophisticated paraphrasing may evade detection.

4. **Comment-Only Content Analysis**: Content/title similarity analysis only applies to comments (posts and replies). Other publication types (votes, edits, moderations) receive a neutral score for this factor.

## Future Improvements

- Challenge completion history tracking
- Machine learning-based content analysis
- Moderation action history integration
